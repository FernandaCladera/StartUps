{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "240dc948",
   "metadata": {},
   "source": [
    "# **AI Research Assistant**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5828b425",
   "metadata": {},
   "source": [
    "AI assitant that discovers, filters, and analyzes web content using Crawö4AI's URL Seeder to:\n",
    "\n",
    "* Discover all available URLs without crawling them first.\n",
    "* Score and rank them by relevance using AI\n",
    "* Crawl only the most relevant content\n",
    "* Generate research insights with proper citations.\n",
    "\n",
    "**About the research assistant** :\n",
    "\n",
    "A smart research assistant that:\n",
    "\n",
    "1. Takes any research query (eg. Knowledge graphs)\n",
    "2. Discovers relevant articles from news sites\n",
    "3. Ranks them by relevance using BM25 scoring\n",
    "4. Crawls only the top-ranked articles\n",
    "5. Synthesizes findings into a comprehensive report\n",
    "   \n",
    "\n",
    "## Pipeline Overview\n",
    "\n",
    "User Query -> Query Enhancement -> URL Discovery -> Relevance Scoring -> Smart Crawling -> AI Synthesis. -> Research Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a10af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment ready :) All dependencies loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from dataclasses import dataclass, asdict\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "#Rich for beutiful console output\n",
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "from rich.table import Table\n",
    "from rich.progress import Progress, SpinnerColumn, TextColumn\n",
    "\n",
    "# Crawl4AI imports for intelligent crawling\n",
    "from crawl4ai import (\n",
    "    AsyncWebCrawler,\n",
    "    BrowserConfig,\n",
    "    CrawlerRunConfig,\n",
    "    AsyncUrlSeeder,\n",
    "    SeedingConfig,\n",
    "    AsyncLogger,\n",
    "    PruningContentFilter,\n",
    "    DefaultMarkdownGenerator\n",
    ")\n",
    "\n",
    "\n",
    "# LiteLLM for AI capabilities\n",
    "import litellm\n",
    "\n",
    "# Initialize Rich console for pretty outputs\n",
    "console=Console()\n",
    "\n",
    "print(\"Environment ready :) All dependencies loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d94a5dc",
   "metadata": {},
   "source": [
    "## Step 1: Configuration and Data Classes\n",
    "\n",
    "Here we define the research pipeline configuration. These dataclasses act as out control center, allowing us to fine-tune every aspect of the research process. Think of them as the settings panel for the research assistant, from discovery limits to AI model choices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "842fd207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────── Settings ────────────────────────────────────────────────────╮\n",
       "│ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Research Configuration</span>                                                                                          │\n",
       "│  Domain: www.bbc.com/sport                                                                                      │\n",
       "│  Max Discovery: 100                                                                                             │\n",
       "│  Max Crawl: 10                                                                                                  │\n",
       "│  AI Model: openai/gpt-4o-mini                                                                                   │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────────── Settings ────────────────────────────────────────────────────╮\n",
       "│ \u001b[1;36mResearch Configuration\u001b[0m                                                                                          │\n",
       "│  Domain: www.bbc.com/sport                                                                                      │\n",
       "│  Max Discovery: 100                                                                                             │\n",
       "│  Max Crawl: 10                                                                                                  │\n",
       "│  AI Model: openai/gpt-4o-mini                                                                                   │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@dataclass\n",
    "class ResearchConfig:\n",
    "        \"\"\"\n",
    "        Configuration for the research pipeline\n",
    "        \n",
    "        This class controls every aspect of our research assistant:\n",
    "        - How many URLs to discover and crawl\n",
    "        - Which scoring methods to use\n",
    "        - Whether to use AI enhancement\n",
    "        - Output preferences\n",
    "        \"\"\"\n",
    "        \n",
    "        # Core Settings\n",
    "        domain: str= \"www.bbc.com/sport\"\n",
    "        max_urls_discovery: int =100    # Cast a wide net initially\n",
    "        max_urls_to_crawl: int=10       # But only crawl the best\n",
    "        top_k_urls: int=10              # Focus on top results\n",
    "        \n",
    "        # Scoring and filtering\n",
    "        score_threshold: float=0.3      # Minimum relevance score\n",
    "        scoring_method: str=\"bm25\"      # BM25 is great for relevance\n",
    "        \n",
    "        # AI and processing\n",
    "        use_llm_enhancement: bool=True  # Enhance queries with AI\n",
    "        llm_model: str=\"openai/gpt-4o-mini\" # Fast and capable\n",
    "        \n",
    "        # URL discovery options\n",
    "        extract_head_metada: bool = False   # Get titles, descriptions\n",
    "        live_check: bool= True              # Verify URLs are accessible\n",
    "        force_refresh: bool= True           # Bypass cache\n",
    "        \n",
    "        # Crawler settings\n",
    "        max_concurrent_crawls: int=5        # Parallel crawling\n",
    "        timeout: int = 30000                # 30 second timeout\n",
    "        headless: bool = True               # No browser window\n",
    "        \n",
    "        # Output settings\n",
    "        output_dir: Path = Path(\"research_results\")\n",
    "        verbose: bool=True\n",
    "\n",
    "@dataclass\n",
    "class ResearchQuery:\n",
    "    \"\"\"Container for research query and metadata \"\"\"\n",
    "    original_query: str\n",
    "    enhanced_query: Optional[str] = None\n",
    "    search_patterns: List[str] = None\n",
    "    timestamp: str = None\n",
    "    \n",
    "@dataclass\n",
    "class ResearchResult:\n",
    "    \"\"\"Container for research results\"\"\"\n",
    "    query: ResearchQuery\n",
    "    discovered_urls: List[Dict]\n",
    "    crawled_content: List[Dict]\n",
    "    synthesis: str\n",
    "    citations: List[Dict]\n",
    "    metadata: Dict\n",
    "\n",
    "# Create default configuration\n",
    "config= ResearchConfig()\n",
    "console.print(Panel(\n",
    "    f\"[bold cyan]Research Configuration[/bold cyan]\\n\"\n",
    "    f\" Domain: {config.domain}\\n\"\n",
    "    f\" Max Discovery: {config.max_urls_discovery}\\n\"\n",
    "    f\" Max Crawl: {config.max_urls_to_crawl}\\n\"\n",
    "    f\" AI Model: {config.llm_model}\",\n",
    "    title=\"Settings\"\n",
    "))\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
