{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "240dc948",
   "metadata": {},
   "source": [
    "# **AI Research Assistant**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5828b425",
   "metadata": {},
   "source": [
    "AI assitant that discovers, filters, and analyzes web content using Crawö4AI's URL Seeder to:\n",
    "\n",
    "* Discover all available URLs without crawling them first.\n",
    "* Score and rank them by relevance using AI\n",
    "* Crawl only the most relevant content\n",
    "* Generate research insights with proper citations.\n",
    "\n",
    "**About the research assistant** :\n",
    "\n",
    "A smart research assistant that:\n",
    "\n",
    "1. Takes any research query (eg. Knowledge graphs)\n",
    "2. Discovers relevant articles from news sites\n",
    "3. Ranks them by relevance using BM25 scoring\n",
    "4. Crawls only the top-ranked articles\n",
    "5. Synthesizes findings into a comprehensive report\n",
    "   \n",
    "\n",
    "## Pipeline Overview\n",
    "\n",
    "User Query -> Query Enhancement -> URL Discovery -> Relevance Scoring -> Smart Crawling -> AI Synthesis. -> Research Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a10af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment ready :) All dependencies loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from dataclasses import dataclass, asdict\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "#Rich for beutiful console output\n",
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "from rich.table import Table\n",
    "from rich.progress import Progress, SpinnerColumn, TextColumn\n",
    "\n",
    "# Crawl4AI imports for intelligent crawling\n",
    "from crawl4ai import (\n",
    "    AsyncWebCrawler,\n",
    "    BrowserConfig,\n",
    "    CrawlerRunConfig,\n",
    "    AsyncUrlSeeder,\n",
    "    SeedingConfig,\n",
    "    AsyncLogger,\n",
    "    PruningContentFilter,\n",
    "    DefaultMarkdownGenerator\n",
    ")\n",
    "\n",
    "\n",
    "# LiteLLM for AI capabilities\n",
    "import litellm\n",
    "\n",
    "# Initialize Rich console for pretty outputs\n",
    "console=Console()\n",
    "\n",
    "print(\"Environment ready :) All dependencies loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d94a5dc",
   "metadata": {},
   "source": [
    "## Step 1: Configuration and Data Classes\n",
    "\n",
    "Here we define the research pipeline configuration. These dataclasses act as out control center, allowing us to fine-tune every aspect of the research process. Think of them as the settings panel for the research assistant, from discovery limits to AI model choices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "842fd207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────── Settings ────────────────────────────────────────────────────╮\n",
       "│ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Research Configuration</span>                                                                                          │\n",
       "│  Domain: www.bbc.com/sport                                                                                      │\n",
       "│  Max Discovery: 100                                                                                             │\n",
       "│  Max Crawl: 10                                                                                                  │\n",
       "│  AI Model: openai/gpt-4o-mini                                                                                   │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────────── Settings ────────────────────────────────────────────────────╮\n",
       "│ \u001b[1;36mResearch Configuration\u001b[0m                                                                                          │\n",
       "│  Domain: www.bbc.com/sport                                                                                      │\n",
       "│  Max Discovery: 100                                                                                             │\n",
       "│  Max Crawl: 10                                                                                                  │\n",
       "│  AI Model: openai/gpt-4o-mini                                                                                   │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@dataclass\n",
    "class ResearchConfig:\n",
    "        \"\"\"\n",
    "        Configuration for the research pipeline\n",
    "        \n",
    "        This class controls every aspect of our research assistant:\n",
    "        - How many URLs to discover and crawl\n",
    "        - Which scoring methods to use\n",
    "        - Whether to use AI enhancement\n",
    "        - Output preferences\n",
    "        \"\"\"\n",
    "        \n",
    "        # Core Settings\n",
    "        domain: str= \"www.bbc.com/sport\"\n",
    "        max_urls_discovery: int =100    # Cast a wide net initially\n",
    "        max_urls_to_crawl: int=10       # But only crawl the best\n",
    "        top_k_urls: int=10              # Focus on top results\n",
    "        \n",
    "        # Scoring and filtering\n",
    "        score_threshold: float=0.3      # Minimum relevance score\n",
    "        scoring_method: str=\"bm25\"      # BM25 is great for relevance\n",
    "        \n",
    "        # AI and processing\n",
    "        use_llm_enhancement: bool=True  # Enhance queries with AI\n",
    "        llm_model: str=\"openai/gpt-4o-mini\" # Fast and capable\n",
    "        \n",
    "        # URL discovery options\n",
    "        extract_head_metada: bool = False   # Get titles, descriptions\n",
    "        live_check: bool= True              # Verify URLs are accessible\n",
    "        force_refresh: bool= True           # Bypass cache\n",
    "        \n",
    "        # Crawler settings\n",
    "        max_concurrent_crawls: int=5        # Parallel crawling\n",
    "        timeout: int = 30000                # 30 second timeout\n",
    "        headless: bool = True               # No browser window\n",
    "        \n",
    "        # Output settings\n",
    "        output_dir: Path = Path(\"research_results\")\n",
    "        verbose: bool=True\n",
    "\n",
    "@dataclass\n",
    "class ResearchQuery:\n",
    "    \"\"\"Container for research query and metadata \"\"\"\n",
    "    original_query: str\n",
    "    enhanced_query: Optional[str] = None\n",
    "    search_patterns: List[str] = None\n",
    "    timestamp: str = None\n",
    "    \n",
    "@dataclass\n",
    "class ResearchResult:\n",
    "    \"\"\"Container for research results\"\"\"\n",
    "    query: ResearchQuery\n",
    "    discovered_urls: List[Dict]\n",
    "    crawled_content: List[Dict]\n",
    "    synthesis: str\n",
    "    citations: List[Dict]\n",
    "    metadata: Dict\n",
    "\n",
    "# Create default configuration\n",
    "config= ResearchConfig()\n",
    "console.print(Panel(\n",
    "    f\"[bold cyan]Research Configuration[/bold cyan]\\n\"\n",
    "    f\" Domain: {config.domain}\\n\"\n",
    "    f\" Max Discovery: {config.max_urls_discovery}\\n\"\n",
    "    f\" Max Crawl: {config.max_urls_to_crawl}\\n\"\n",
    "    f\" AI Model: {config.llm_model}\",\n",
    "    title=\"Settings\"\n",
    "))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7733a6",
   "metadata": {},
   "source": [
    "## Step 2: Query Enhancement with AI\n",
    "\n",
    "Not all search queries are created equal. Here we use AI to transform simple queries into comprehensive search strategies. The LLM analyzes your query, extracts key concepts, and generates related terms - turning \"football news\" into a rich set of search patters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf9c180d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63c8f3ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> Enhancing query: 'knowledge graphs news...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[36m Enhancing query: 'knowledge graphs news\u001b[0m\u001b[36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────── Query Enhancement ───────────────────────────────────────────────╮\n",
       "│ <span style=\"color: #008000; text-decoration-color: #008000\"> Enhanced Query:</span> latest advancements and applications of knowledge graphs in news and media                     │\n",
       "│ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Key terms: knowledge graphs, semantic web, data integration, ontology, graph databases, machine learning, </span>     │\n",
       "│ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">information retrieval</span>                                                                                           │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────── Query Enhancement ───────────────────────────────────────────────╮\n",
       "│ \u001b[32m Enhanced Query:\u001b[0m latest advancements and applications of knowledge graphs in news and media                     │\n",
       "│ \u001b[2m Key terms: knowledge graphs, semantic web, data integration, ontology, graph databases, machine learning, \u001b[0m     │\n",
       "│ \u001b[2minformation retrieval\u001b[0m                                                                                           │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "async def enhance_query_with_llm(query: str,config:ResearchConfig) -> ResearchQuery:\n",
    "    \"\"\"\n",
    "    Transform simple queries into comprehensive search strategies\n",
    "    Why enhance queries?\n",
    "    - User often use simple terms (\"football news\")\n",
    "    - But relevant content might use varied terminology\n",
    "    - AI helps capture all relevant variations    \n",
    "    \"\"\"\n",
    "    \n",
    "    console.print(f\"\\n[cyan] Enhancing query: '{query}...[/cyan]\")\n",
    "    try:\n",
    "        # Ask AI to analyze and expand the query\n",
    "        response = await litellm.acompletion(\n",
    "            model=config.llm_model,\n",
    "            messages=[{\n",
    "                \"role\":\"user\",\n",
    "                \"content\":f\"\"\"Given this research query: \"{query}\"\n",
    "                Extract:\n",
    "                1. Key terms and concepts (as a list)\n",
    "                2. Related search terms\n",
    "                3. A more specific/enhanced version of the query\n",
    "                \n",
    "                Return as JSON:\n",
    "                {{\n",
    "                    \"key_terms\":[\"term1\",\"term2\"],\n",
    "                    \"related_terms\": [\"related1\",\"related2\"],\n",
    "                    \"enhanced_query\": \"enhanced version of query\"\n",
    "                }}\n",
    "                \n",
    "               \"\"\"\n",
    "            }],\n",
    "            temperature=0.3, #Low termperature for consistency\n",
    "            response_format={\"type\":\"json_object\"}\n",
    "        )\n",
    "        \n",
    "        data=json.loads(response.choices[0].message.content)\n",
    "        \n",
    "        # Create search patterns from extracted terms\n",
    "        # These patterns help the URL seeder find relevant pages\n",
    "        \n",
    "        all_terms= data[\"key_terms\"] + data [\"related_terms\"]\n",
    "        #patterns = [f\"*{term.lower()}*\" for term in all_terms]\n",
    "        \n",
    "        result = ResearchQuery(\n",
    "            original_query=query,\n",
    "            enhanced_query=data[\"enhanced_query\"],\n",
    "            search_patterns= \"\", #patterns[:10], #Limit to 10 patterns\n",
    "            timestamp=datetime.now().isoformat()\n",
    "        )\n",
    "        \n",
    "        # Show the enhancement\n",
    "        console.print(Panel(\n",
    "            f\"[green] Enhanced Query:[/green] {result.enhanced_query}\\n\"\n",
    "            f\"[dim] Key terms: {', '.join(data['key_terms'])}[/dim]\",\n",
    "            title = \"Query Enhancement\"\n",
    "        ))\n",
    "    \n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        console.print(f\"[yellow] Enhancement failed, using original query: {e}[/yellow]\")\n",
    "        #Fallback to simple tokenization\n",
    "        words= query.lower().split()\n",
    "        patterns =[f\"*{word}*\" for word in words if len(word)>2]\n",
    "        \n",
    "        return ResearchQuery(\n",
    "            original_query=query,\n",
    "            enhanced_query=query,\n",
    "            search_patterns=patterns,\n",
    "            timestamp=datetime.now().isoformat()\n",
    "        )\n",
    "        \n",
    "# Example usage\n",
    "test_query= \"knowledge graphs news\"\n",
    "enhanced = await enhance_query_with_llm(test_query,config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
